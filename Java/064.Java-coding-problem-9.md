## üìù Coding Problem 9: Remove Duplicates from a List

**Problem Statement:**
Given a `List<String>`, return a new `List<String>` containing only the unique elements from the original list, preserving the original order of first appearance.

**Example:**
Input: `List<String> words = Arrays.asList("apple", "banana", "apple", "orange", "banana", "grape");`
Output: `["apple", "banana", "orange", "grape"]`

---

### Approach 1: Pre-Java 8 (Imperative Style - Using LinkedHashSet)

**Thought Process:**
The most efficient way to remove duplicates while preserving insertion order is to use a `LinkedHashSet`. A `LinkedHashSet` maintains the order of elements as they are inserted and does not allow duplicates. We can add all elements from the input list to a `LinkedHashSet` and then convert it back to a `List`.

**Implementation:**
```java
import java.util.ArrayList;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Set;
import java.util.Arrays;

public class RemoveDuplicatesPreJava8 {

    public static List<String> removeDuplicates(List<String> words) {
        if (words == null) {
            return new ArrayList<>(); // Or throw IllegalArgumentException
        }
        Set<String> uniqueWords = new LinkedHashSet<>(words);
        return new ArrayList<>(uniqueWords);
    }

    public static void main(String[] args) {
        List<String> words = Arrays.asList("apple", "banana", "apple", "orange", "banana", "grape");
        List<String> uniqueWords = removeDuplicates(words);
        System.out.println("Unique Words (Pre-Java 8): " + uniqueWords);

        List<String> emptyList = Arrays.asList();
        System.out.println("Unique Words (Empty List): " + removeDuplicates(emptyList));
    }
}
```

---

### Approach 2: Post-Java 8 (Functional Style - Using Streams)

**Thought Process:**
Java 8 Streams provide a very concise way to remove duplicates using the `distinct()` intermediate operation. This operation returns a stream consisting of the distinct elements (according to `equals()` and `hashCode()`). We then collect the distinct elements into a new list.

**Implementation:**
```java
import java.util.List;
import java.util.Arrays;
import java.util.stream.Collectors;

public class RemoveDuplicatesPostJava8 {

    public static List<String> removeDuplicates(List<String> words) {
        if (words == null) {
            return List.of(); // Returns an immutable empty list
        }
        return words.stream()
                    .distinct() // Returns a stream with unique elements
                    .collect(Collectors.toList()); // Collects to a new List
    }

    public static void main(String[] args) {
        List<String> words = Arrays.asList("apple", "banana", "apple", "orange", "banana", "grape");
        List<String> uniqueWords = removeDuplicates(words);
        System.out.println("Unique Words (Post-Java 8): " + uniqueWords);

        List<String> emptyList = Arrays.asList();
        System.out.println("Unique Words (Empty List): " + removeDuplicates(emptyList));
    }
}
```

---

### Discussion on Approaches:

- ‚Üí **Readability:** Both approaches are highly readable. The `LinkedHashSet` approach is a well-known idiom for this problem. The Stream API's `distinct()` method is very expressive and concise.
- ‚Üí **Conciseness:** The Stream API solution is more compact.
- ‚Üí **Performance:** Both approaches have similar time complexities (typically O(N) on average, where N is the number of elements, due to hash set operations). The `LinkedHashSet` approach might be marginally faster in some scenarios due to less overhead than stream creation and collection. However, for most practical purposes, the difference is negligible.
- ‚Üí **Order Preservation:** Both methods preserve the original insertion order of the unique elements.
- ‚Üí **Immutability (Post-Java 8):** Note that `List.of()` (used for empty list in Post-Java 8 example) creates an immutable list. If a mutable list is required, `new ArrayList<>()` should be used with `Collectors.toCollection(ArrayList::new)`.
